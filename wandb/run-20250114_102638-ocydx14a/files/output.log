Using cuda device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
[2K---------------------------------38;5;197m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m4,978/500,000 [0m [ [33m0:00:29[0m < [36m0:49:06[0m , [31m168 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | -148     |
| time/              |          |
|    episodes        | 10       |
|    fps             | 170      |
|    time_elapsed    | 29       |
|    total_timesteps | 5000     |
| train/             |          |
|    actor_loss      | 4.95     |
|    critic_loss     | 0.000708 |
|    learning_rate   | 0.001    |
|    n_updates       | 4899     |
---------------------------------
[2K---------------------------------[38;5;197m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m9,979/500,000 [0m [ [33m0:00:56[0m < [36m0:44:18[0m , [31m184 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | -103     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 177      |
|    time_elapsed    | 56       |
|    total_timesteps | 10000    |
| train/             |          |
|    actor_loss      | 6.01     |
|    critic_loss     | 0.000993 |
|    learning_rate   | 0.001    |
|    n_updates       | 9899     |
---------------------------------
[2K---------------------------------0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m14,986/500,000 [0m [ [33m0:01:22[0m < [36m0:43:05[0m , [31m188 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | -109     |
| time/              |          |
|    episodes        | 30       |
|    fps             | 180      |
|    time_elapsed    | 82       |
|    total_timesteps | 15000    |
| train/             |          |
|    actor_loss      | 6.95     |
|    critic_loss     | 0.00119  |
|    learning_rate   | 0.001    |
|    n_updates       | 14899    |
---------------------------------
[2K---------------------------------[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m19,980/500,000 [0m [ [33m0:01:50[0m < [36m0:43:58[0m , [31m182 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | -86.8    |
| time/              |          |
|    episodes        | 40       |
|    fps             | 181      |
|    time_elapsed    | 110      |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | 4.47     |
|    critic_loss     | 0.00166  |
|    learning_rate   | 0.001    |
|    n_updates       | 19899    |
---------------------------------
[2K---------------------------------━[0m[38;5;197m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m24,986/500,000 [0m [ [33m0:02:18[0m < [36m0:43:55[0m , [31m180 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | -70.9    |
| time/              |          |
|    episodes        | 50       |
|    fps             | 181      |
|    time_elapsed    | 138      |
|    total_timesteps | 25000    |
| train/             |          |
|    actor_loss      | 3.09     |
|    critic_loss     | 0.00985  |
|    learning_rate   | 0.001    |
|    n_updates       | 24899    |
---------------------------------
[2K---------------------------------━━━[0m[38;5;197m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m29,966/500,000 [0m [ [33m0:02:45[0m < [36m0:43:23[0m , [31m181 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | -59.5    |
| time/              |          |
|    episodes        | 60       |
|    fps             | 181      |
|    time_elapsed    | 165      |
|    total_timesteps | 30000    |
| train/             |          |
|    actor_loss      | 2.23     |
|    critic_loss     | 0.0185   |
|    learning_rate   | 0.001    |
|    n_updates       | 29899    |
---------------------------------
[2K---------------------------------━━━━━[0m[38;5;197m╸[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m34,965/500,000 [0m [ [33m0:03:13[0m < [36m0:43:10[0m , [31m180 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | -54.9    |
| time/              |          |
|    episodes        | 70       |
|    fps             | 180      |
|    time_elapsed    | 193      |
|    total_timesteps | 35000    |
| train/             |          |
|    actor_loss      | 0.0129   |
|    critic_loss     | 0.00885  |
|    learning_rate   | 0.001    |
|    n_updates       | 34899    |
---------------------------------
[2K---------------------------------━━━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m39,979/500,000 [0m [ [33m0:03:41[0m < [36m0:43:28[0m , [31m176 it/s[0m ]
| rollout/           |          |
|    ep_len_mean     | 500      |
|    ep_rew_mean     | -48.7    |
| time/              |          |
|    episodes        | 80       |
|    fps             | 180      |
|    time_elapsed    | 221      |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | 0.155    |
|    critic_loss     | 0.00141  |
|    learning_rate   | 0.001    |
|    n_updates       | 39899    |
---------------------------------
[2KTraceback (most recent call last):━━━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
[2K  File "/home/jd/Dropbox/TUe/Articles/SISO_RL/train.py", line 53, in <module>━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
    model.learn(total_timesteps=config["total_timesteps"], log_interval=10, progress_bar=True, callback=WandbCallback())
[2K  File "/home/jd/.venv/RL/lib/python3.12/site-packages/stable_baselines3/ddpg/ddpg.py", line 123, in learn━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
    return super().learn(
           ^^^^^^^^^^^^^^
[2K  File "/home/jd/.venv/RL/lib/python3.12/site-packages/stable_baselines3/td3/td3.py", line 222, in learn━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
    return super().learn(
           ^^^^^^^^^^^^^^
[2K  File "/home/jd/.venv/RL/lib/python3.12/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 328, in learn━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
    rollout = self.collect_rollouts(
              ^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/jd/.venv/RL/lib/python3.12/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 557, in collect_rollouts━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
    actions, buffer_actions = self._sample_action(learning_starts, action_noise, env.num_envs)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/jd/.venv/RL/lib/python3.12/site-packages/stable_baselines3/common/off_policy_algorithm.py", line 390, in _sample_action━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
    unscaled_action, _ = self.predict(self._last_obs, deterministic=False)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/jd/.venv/RL/lib/python3.12/site-packages/stable_baselines3/common/base_class.py", line 556, in predict━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
    return self.policy.predict(observation, state, episode_start, deterministic)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/jd/.venv/RL/lib/python3.12/site-packages/stable_baselines3/common/policies.py", line 365, in predict━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
    obs_tensor, vectorized_env = self.obs_to_tensor(observation)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/jd/.venv/RL/lib/python3.12/site-packages/stable_baselines3/common/policies.py", line 276, in obs_to_tensor━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
    obs_tensor = obs_as_tensor(observation, self.device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2K  File "/home/jd/.venv/RL/lib/python3.12/site-packages/stable_baselines3/common/utils.py", line 476, in obs_as_tensor━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
    def obs_as_tensor(obs: Union[np.ndarray, Dict[str, np.ndarray]], device: th.device) -> Union[th.Tensor, TensorDict]:

[2KKeyboardInterrupt;197m━━━━━━━━━━━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
[35m   9%[0m [38;5;197m━━━━━━━━━━━━━━━[0m[38;5;237m╺[0m[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[0m [32m42,709/500,000 [0m [ [33m0:03:57[0m < [36m0:44:19[0m , [31m172 it/s[0m ]
