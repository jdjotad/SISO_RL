2025-01-14 10:26:38,941 INFO    MainThread:240972 [wandb_setup.py:_flush():68] Current SDK version is 0.19.2
2025-01-14 10:26:38,941 INFO    MainThread:240972 [wandb_setup.py:_flush():68] Configure stats pid to 240972
2025-01-14 10:26:38,942 INFO    MainThread:240972 [wandb_setup.py:_flush():68] Loading settings from /home/jd/.config/wandb/settings
2025-01-14 10:26:38,942 INFO    MainThread:240972 [wandb_setup.py:_flush():68] Loading settings from /home/jd/Dropbox/TUe/Articles/SISO_RL/wandb/settings
2025-01-14 10:26:38,942 INFO    MainThread:240972 [wandb_setup.py:_flush():68] Loading settings from environment variables
2025-01-14 10:26:38,942 INFO    MainThread:240972 [wandb_init.py:_log_setup():523] Logging user logs to /home/jd/Dropbox/TUe/Articles/SISO_RL/wandb/run-20250114_102638-ocydx14a/logs/debug.log
2025-01-14 10:26:38,943 INFO    MainThread:240972 [wandb_init.py:_log_setup():524] Logging internal logs to /home/jd/Dropbox/TUe/Articles/SISO_RL/wandb/run-20250114_102638-ocydx14a/logs/debug-internal.log
2025-01-14 10:26:38,943 INFO    MainThread:240972 [wandb_init.py:init():641] calling init triggers
2025-01-14 10:26:38,943 INFO    MainThread:240972 [wandb_init.py:init():647] wandb.init called with sweep_config: {}
config: {'policy_type': 'MlpPolicy', 'total_timesteps': 500000, 'env_name': 'RL Variable Reference'}
2025-01-14 10:26:38,943 INFO    MainThread:240972 [wandb_init.py:init():674] starting backend
2025-01-14 10:26:39,166 INFO    MainThread:240972 [wandb_init.py:init():678] sending inform_init request
2025-01-14 10:26:39,174 INFO    MainThread:240972 [backend.py:_multiprocessing_setup():104] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-01-14 10:26:39,174 INFO    MainThread:240972 [wandb_init.py:init():693] backend started and connected
2025-01-14 10:26:39,176 INFO    MainThread:240972 [wandb_init.py:init():786] updated telemetry
2025-01-14 10:26:39,183 INFO    MainThread:240972 [wandb_init.py:init():818] communicating run to backend with 90.0 second timeout
2025-01-14 10:26:39,532 INFO    MainThread:240972 [wandb_init.py:init():868] starting run threads in backend
2025-01-14 10:26:39,640 INFO    MainThread:240972 [wandb_run.py:_console_start():2415] atexit reg
2025-01-14 10:26:39,640 INFO    MainThread:240972 [wandb_run.py:_redirect():2265] redirect: wrap_raw
2025-01-14 10:26:39,642 INFO    MainThread:240972 [wandb_run.py:_redirect():2330] Wrapping output streams.
2025-01-14 10:26:39,642 INFO    MainThread:240972 [wandb_run.py:_redirect():2355] Redirects installed.
2025-01-14 10:26:39,644 INFO    MainThread:240972 [wandb_init.py:init():910] run started, returning control to user process
2025-01-14 10:26:40,779 INFO    MainThread:240972 [wandb_run.py:_config_callback():1283] config_cb None None {'algo': 'DDPG', 'policy_class': "<class 'stable_baselines3.td3.policies.TD3Policy'>", 'device': 'cuda', 'verbose': 1, 'policy_kwargs': "{'n_critics': 1}", 'num_timesteps': 0, '_total_timesteps': 500000, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'NormalActionNoise(mu=[0.], sigma=[0.1])', 'start_time': 1736846800778337071, 'learning_rate': 0.001, 'tensorboard_log': 'None', '_last_obs': '[[ 0.64811 -0.42444]]', '_last_episode_starts': '[ True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x7bbf41f0b500>', '_vec_normalize_env': 'None', 'observation_space': 'Box(-1.0, 1.0, (2,), float32)', 'action_space': 'Box(-1.0, 1.0, (1,), float32)', 'n_envs': 1, 'buffer_size': 1000000, 'batch_size': 256, 'learning_starts': 100, 'tau': 0.005, 'gamma': 0.99, 'gradient_steps': 1, 'optimize_memory_usage': 'False', 'replay_buffer': '<stable_baselines3.common.buffers.ReplayBuffer object at 0x7bbf3d4e5520>', 'replay_buffer_class': "<class 'stable_baselines3.common.buffers.ReplayBuffer'>", 'replay_buffer_kwargs': '{}', '_episode_storage': 'None', 'train_freq': "TrainFreq(frequency=1, unit=<TrainFrequencyUnit.STEP: 'step'>)", 'use_sde_at_warmup': 'False', 'policy_delay': 1, 'target_noise_clip': 0.0, 'target_policy_noise': 0.1, 'lr_schedule': '<function get_schedule_fn.<locals>.<lambda> at 0x7bbf3d54ec00>', 'policy': 'TD3Policy(\n  (actor): Actor(\n    (features_extractor): FlattenExtractor(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n    )\n    (mu): Sequential(\n      (0): Linear(in_features=2, out_features=400, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=400, out_features=300, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=300, out_features=1, bias=True)\n      (5): Tanh()\n    )\n  )\n  (actor_target): Actor(\n    (features_extractor): FlattenExtractor(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n    )\n    (mu): Sequential(\n      (0): Linear(in_features=2, out_features=400, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=400, out_features=300, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=300, out_features=1, bias=True)\n      (5): Tanh()\n    )\n  )\n  (critic): ContinuousCritic(\n    (features_extractor): FlattenExtractor(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=3, out_features=400, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=400, out_features=300, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=300, out_features=1, bias=True)\n    )\n  )\n  (critic_target): ContinuousCritic(\n    (features_extractor): FlattenExtractor(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n    )\n    (qf0): Sequential(\n      (0): Linear(in_features=3, out_features=400, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=400, out_features=300, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=300, out_features=1, bias=True)\n    )\n  )\n)', 'actor': 'Actor(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mu): Sequential(\n    (0): Linear(in_features=2, out_features=400, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=400, out_features=300, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=300, out_features=1, bias=True)\n    (5): Tanh()\n  )\n)', 'actor_target': 'Actor(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mu): Sequential(\n    (0): Linear(in_features=2, out_features=400, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=400, out_features=300, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=300, out_features=1, bias=True)\n    (5): Tanh()\n  )\n)', 'critic': 'ContinuousCritic(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=3, out_features=400, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=400, out_features=300, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=300, out_features=1, bias=True)\n  )\n)', 'critic_target': 'ContinuousCritic(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (qf0): Sequential(\n    (0): Linear(in_features=3, out_features=400, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=400, out_features=300, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=300, out_features=1, bias=True)\n  )\n)', 'actor_batch_norm_stats': '[]', 'critic_batch_norm_stats': '[]', 'actor_batch_norm_stats_target': '[]', 'critic_batch_norm_stats_target': '[]', '_logger': '<stable_baselines3.common.logger.Logger object at 0x7bbf2546d370>'}
2025-01-14 10:30:38,487 WARNING MsgRouterThr:240972 [router.py:message_loop():75] message_loop has been closed
